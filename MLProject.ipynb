{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPu5Mou4XLXlL/Jnd8SEuJh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21f1002963/Colab/blob/main/MLProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ag0A8Au4-Lyt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "99jlJPRh9dm_"
      },
      "outputs": [],
      "source": [
        "train_data=pd.read_csv(\"train_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_data.copy()\n",
        "train['purchaseFlag'] = (train['purchaseValue'] > 0).astype(int)\n",
        "y_class = train['purchaseFlag']\n",
        "y_reg = train['purchaseValue']\n",
        "train = train.drop(columns=['purchaseValue', 'purchaseFlag'])"
      ],
      "metadata": {
        "id": "UsWJnSOT94hZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.dropna(subset=['pageViews'])\n",
        "y_class = y_class.loc[train.index]\n",
        "y_reg = y_reg.loc[train.index]"
      ],
      "metadata": {
        "id": "XODKq9iT98CQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class CustomPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.cols_to_drop = [\n",
        "            'trafficSource.adContent',\n",
        "            'trafficSource.adwordsClickInfo.adNetworkType',\n",
        "            'trafficSource.adwordsClickInfo.isVideoAd',\n",
        "            'trafficSource.adwordsClickInfo.page',\n",
        "            'trafficSource.adwordsClickInfo.slot',\n",
        "            'device.screenResolution',\n",
        "            'trafficSource.keyword',\n",
        "            'screenSize',\n",
        "            'device.mobileDeviceBranding',\n",
        "            'device.mobileInputSelector',\n",
        "            'userId',\n",
        "            'trafficSource.campaign',\n",
        "            'device.mobileDeviceMarketingName',\n",
        "            'device.operatingSystemVersion',\n",
        "            'device.flashVersion',\n",
        "            'totals.visits',\n",
        "            'geoNetwork.networkLocation',\n",
        "            'browserMajor',\n",
        "            'device.browserSize',\n",
        "            'socialEngagementType',\n",
        "            'locationZone',\n",
        "            'device.mobileDeviceModel',\n",
        "            'device.language',\n",
        "            'device.browserVersion',\n",
        "            'device.screenColors',\n",
        "        ]\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        # Drop noisy columns\n",
        "        X.drop(columns=[col for col in self.cols_to_drop if col in X.columns], inplace=True, errors='ignore')\n",
        "\n",
        "        # Basic type fixes\n",
        "        X['trafficSource.isTrueDirect'] = X['trafficSource.isTrueDirect'].fillna(False).astype(int)\n",
        "        X['device.isMobile'] = X['device.isMobile'].astype(int)\n",
        "\n",
        "        def bucket_referral(path):\n",
        "            path = str(path)\n",
        "            if path == '/':\n",
        "                return 'direct_landing'\n",
        "            elif 'offer' in path or 'deal' in path or 'discount' in path:\n",
        "                return 'known_referrer'\n",
        "            elif 'mail' in path:\n",
        "                return 'known_referrer'\n",
        "            elif 'google-merchandise-store' in path:\n",
        "                return 'known_referrer'\n",
        "            elif '/yt/' in path:\n",
        "                return 'known_referrer'\n",
        "            elif '/a/google.com/' in path:\n",
        "                return 'known_referrer'\n",
        "            elif 'redirect' in path or 'l.php' in path or '/url' in path:\n",
        "                return 'known_referrer'\n",
        "            elif path == 'no_referral' or path.strip() == '':\n",
        "                return 'unknown'\n",
        "            else:\n",
        "                return 'unknown'\n",
        "\n",
        "        X['trafficSource.referralPath'] = X['trafficSource.referralPath'].fillna('no_referral').apply(bucket_referral)\n",
        "        X['totals.bounces'] = X['totals.bounces'].fillna(2).astype(float)\n",
        "\n",
        "        X['new_visits'] = X['new_visits'].fillna(0)\n",
        "\n",
        "        X['geoNetwork.city'] = X['geoNetwork.city'].replace({'not available in demo dataset': 'Unknown','(not set)': 'Not_Set'})\n",
        "        top_cities = X['geoNetwork.city'].value_counts().head(70).index.tolist()\n",
        "        X['geoNetwork.city'] = X['geoNetwork.city'].apply(lambda x: x if x in top_cities else 'Other')\n",
        "\n",
        "        X['geoNetwork.metro'] = X['geoNetwork.metro'].replace({'not available in demo dataset': 'Unknown','(not set)': 'Not_Set'})\n",
        "        top_metros = X['geoNetwork.metro'].value_counts().head(40).index.tolist()\n",
        "        X['geoNetwork.metro'] = X['geoNetwork.metro'].apply(lambda x: x if x in top_metros else 'Other')\n",
        "\n",
        "        # Log transform\n",
        "        def session_bucket(n):\n",
        "            if n == 1:\n",
        "                return 'first_time'\n",
        "            elif n <= 3:\n",
        "                return 'return_early'\n",
        "            elif n <= 7:\n",
        "                return 'return_mid'\n",
        "            elif n <= 15:\n",
        "                return 'return_late'\n",
        "            else:\n",
        "                return 'loyal_or_power'\n",
        "        X['session_bucket'] = X['sessionNumber'].apply(session_bucket)\n",
        "        X['sessionNumber'] = np.log1p(X['sessionNumber'])\n",
        "\n",
        "        # Time features\n",
        "        if 'sessionStart' in X.columns:\n",
        "            dt = pd.to_datetime(X['sessionStart'], unit='s')\n",
        "            X['hour'] = dt.dt.hour\n",
        "            X['min'] = dt.dt.minute\n",
        "\n",
        "        if 'date' in X.columns:\n",
        "            X['date'] = pd.to_datetime(X['date'], format='%Y%m%d')\n",
        "            X['day'] = X['date'].dt.day\n",
        "            X['month'] = X['date'].dt.month\n",
        "            X['year'] = X['date'].dt.year\n",
        "            X['quarter'] = X['date'].dt.quarter\n",
        "            X['semester'] = np.where(X['quarter'].isin([1, 2]), 1, 2)\n",
        "            X['day_of_week'] = X['date'].dt.dayofweek\n",
        "            X['is_weekend'] = X['day_of_week'].isin([5, 6]).astype(int)\n",
        "            X.drop(['date'], axis=1, inplace=True)\n",
        "\n",
        "        X.drop(['sessionStart'], axis=1, errors='ignore', inplace=True)\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "wgFKG8Ec-4Jn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "# from category_encoders import TargetEncoder # Assuming TargetEncoder is used and needs importing\n",
        "\n",
        "# high_card_cols = ['geoNetwork.region', 'trafficSource.referralPath', 'userChannel', 'locationCountry', 'trafficSource.medium', 'geoNetwork.subContinent', 'trafficSource', 'geoNetwork.metro', 'geoNetwork.city']\n",
        "\n",
        "low_card_cols = ['geoNetwork.networkDomain', 'geoNetwork.continent', 'deviceType', 'geoCluster', 'os', 'browser', 'geoNetwork.region', 'trafficSource.referralPath', 'userChannel', 'locationCountry', 'trafficSource.medium', 'geoNetwork.subContinent', 'trafficSource', 'geoNetwork.metro', 'geoNetwork.city', 'session_bucket' ]\n",
        "\n",
        "# Set up column transformer\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first'), low_card_cols)\n",
        "], remainder='passthrough')  # Keeps other features (numeric, target-encoded)\n",
        "\n",
        "final_preprocessor = Pipeline([\n",
        "    ('onehot_and_pass', preprocessor),  # your ColumnTransformer\n",
        "])\n",
        "\n",
        "# Assuming CustomPreprocessor is a custom class defined elsewhere and doesn't need importing\n",
        "# Assuming TargetEncoderWithKFold is a custom class defined elsewhere and doesn't need importing\n",
        "\n",
        "\n",
        "# Full pipeline\n",
        "clf_pipeline = Pipeline([\n",
        "    ('custom_cleaning', CustomPreprocessor()),\n",
        "    # ('target_encoding', TargetEncoderWithKFold(cols=high_card_cols, log_target=True)),\n",
        "    ('ohe_and_rest', final_preprocessor),\n",
        "])\n",
        "\n",
        "# Train\n",
        "X_train_processed = clf_pipeline.fit_transform(train, y_class)\n",
        "# print(X_train_processed.info())\n",
        "\n",
        "# Grid Search CV\n",
        "n_estimators = [20,40, 60, 80, 100,120]\n",
        "max_features = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "max_depth = [2,8,None]\n",
        "max_samples = [0.25, 0.5,0.75,1.0]\n",
        "param_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "              'max_samples':max_samples,\n",
        "              'max_depth': max_depth\n",
        "             }\n",
        "\n",
        "# rf_random = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "rf_random = RandomizedSearchCV(\n",
        "    estimator=RandomForestClassifier(),\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=30,          # only 30 random combos\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "rf_random.fit(X_train_processed, y_class)\n",
        "rf_random.best_params_\n",
        "rf_random.best_score_\n",
        "\n",
        "# X_test_processed = clf_pipeline.transform(test_data)\n",
        "# print(X_test_processed.info())\n",
        "# purchase_flags = rf_random.predict(X_test_processed)\n",
        "\n",
        "# mask = y_class == 1\n",
        "# train_reg = train.loc[mask]\n",
        "# y_reg_filtered = y_reg.loc[mask]\n",
        "\n",
        "\n",
        "# reg_pipeline = Pipeline([\n",
        "#     ('custom_cleaning', CustomPreprocessor()),\n",
        "#     # ('target_encoding', TargetEncoderWithKFold(cols=high_card_cols, log_target=True)),\n",
        "#     ('ohe_and_rest', final_preprocessor),\n",
        "#     ('reg_model', GradientBoostingRegressor())\n",
        "# ])\n",
        "# reg_pipeline.fit(train_reg, y_reg_filtered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNcfm3yP992y",
        "outputId": "5f3a0aec-0080-4d25-d380-96436397190d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-4224869630.py:43: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  X['trafficSource.isTrueDirect'] = X['trafficSource.isTrueDirect'].fillna(False).astype(int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9639701762703099)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_random.best_params_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF9yOjqAOc8q",
        "outputId": "3c61c9b0-3f52-4eee-8668-4084ba19139f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 80,\n",
              " 'max_samples': 1.0,\n",
              " 'max_features': 0.4,\n",
              " 'max_depth': None}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}